{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation Correction Model Training\n",
    "\n",
    "Some of the images in the training set are rotated in multiples of 90 degrees, which need to be corrected before being used in training or inference.  Detecting and correcting this needs to be much faster than the general classification task, but should it should be doable with a small dataset, since all the images are of buildings.\n",
    "\n",
    "Steps we are going to follow for this:\n",
    "1. Make a copy of the training data but with all the rotated images fixed\n",
    "2. Resize all images to (64,64), which is satisfactory for determining orientation\n",
    "2. Add a fourth channel that contains edges of the image as detected via Canny edge detection\n",
    "4. Create a small CNN that has four outputs: one for each possible orientation\n",
    "5. Unsupervised training: use cv2 to rotate images and then train the CNN to detect the rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alan/projects/venv-jupyter/lib/python3.7/site-packages/pandas/compat/__init__.py:84: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS Type: posix\n",
      "OS Name: Linux\n",
      "OS Release: 4.15.0-50-generic\n",
      "Using Python=3.7.2 (default, Mar 30 2019, 15:56:42) \n",
      "[GCC 5.4.0 20160609]\n",
      "Using Tensorflow=2.0.0-rc2\n",
      "Using Keras=2.2.4-tf\n",
      "GPU Available:  True\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.core.debugger import set_trace\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    " \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_probability as tfp\n",
    "%matplotlib inline\n",
    " \n",
    "print(\"OS Type: %s\" % os.name)\n",
    "print(\"OS Name: %s\" % platform.system())\n",
    "print(\"OS Release: %s\" % platform.release())\n",
    "print(f'Using Python={sys.version}')\n",
    "print(f'Using Tensorflow={tf.__version__}')\n",
    "print(f'Using Keras={keras.__version__}')\n",
    "print(\"GPU Available: \", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from custom_preproc import index_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = 'train_imgs_orientation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
